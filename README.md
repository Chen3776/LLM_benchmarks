# LLM_benchmarks
Reproduced some LLM benchmarks

## Target

### Knowledge and language understanding

MMLU: 57 Subject General knowledge; 
GLUE: Language understanding in different contexts, for chatbots; 
Natural Questions: google questions, wiki answers, for search engines; 
SuperGLUE; 
GPQA: Physicobiological expert problem *448, SOTA model 34%, Human expert 65%; 

### Reasoning ability

GSM8K: 8.5k primary school math problems; 
BigBenchHard, BBH, Complex reasoning; 

### Multiple rounds of open dialogue

MT-bench: Multiple rounds of conversations; 

### programming

CodeXGLUE, comprehensive ability; 
Humaneval, write functional code; 
MBPP, Mostly Basic Python Programming; 
